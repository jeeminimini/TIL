{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ujo2m15sonry"
   },
   "outputs": [],
   "source": [
    "import librosa, librosa.display \n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OORv7lMlpR1u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "images = glob.glob('/home/vislab/Codes/DoLearn_jimin/data/image_plt/*.png')\n",
    "label=pd.read_csv('/home/vislab/Codes/DoLearn_jimin/data/y_label.csv')\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_images=[]\n",
    "mel_labels=[]\n",
    "i=0\n",
    "for fname in images:\n",
    "    image_pil = Image.open(fname).convert('RGB')\n",
    "    image_bw = np.array(image_pil)\n",
    "    mel_images.append(image_bw)\n",
    "    i+=1\n",
    "\n",
    "mel_images=np.array(mel_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mel_images=np.expand_dims(mel_images, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel_images=np.transpose(mel_images,(0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(332, 3, 128, 1876)\n"
     ]
    }
   ],
   "source": [
    "print(mel_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(mel_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "def normalize2(image):\n",
    "    image = (image - mean) / std\n",
    "    # in addition, roll the axis so that they suit pytorch\n",
    "    return torch.tensor(image.swapaxes(-1, 1).swapaxes(2, 3)).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "from torchvision import models\n",
    "model = models.vgg16(pretrained=True).eval()\n",
    "model.to(device)\n",
    "\n",
    "model.classifier[6].out_features=2\n",
    "model.features[0].in_channels=1\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(mel_images, label['0'], test_size=0.33, random_state=42, stratify = label['0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "x_train=torch.FloatTensor(np.array(x_train)).cuda()\n",
    "y_train=torch.LongTensor(np.array(y_train)).cuda()\n",
    "x_test=torch.FloatTensor(np.array(x_test)).cuda()\n",
    "y_test=torch.LongTensor(np.array(y_test)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=torch.utils.data.TensorDataset(x_train,y_train)\n",
    "train_loader=torch.utils.data.DataLoader(train_dataset,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "s7O0UuwzpdT1"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 612.00 MiB (GPU 0; 23.70 GiB total capacity; 21.39 GiB already allocated; 72.62 MiB free; 21.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-85e300f97fd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dolearn-gpu/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dolearn-gpu/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dolearn-gpu/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/dolearn-gpu/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dolearn-gpu/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/dolearn-gpu/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 612.00 MiB (GPU 0; 23.70 GiB total capacity; 21.39 GiB already allocated; 72.62 MiB free; 21.63 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model.train()\n",
    "for i in range(15):\n",
    "    for X, Y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "    print(i,cost.item(),accuracy_score(Y.cpu(),hypothesis.cpu().detach().numpy().argmax(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVgq1oi1YzlB"
   },
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVYfFEA6pfv1"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "label_list = []\n",
    "i = 1\n",
    "label = glob.glob('C:\\Users\\vislab\\Documents\\두런두런\\permission to safe\\label\\*.json',recursive=True)\n",
    "for label_path in label:\n",
    "    with open(label_path,'r',encoding=\"UTF-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "    #print(json.dumps(json_data,indent = \"\\t\",ensure_ascii=False))\n",
    "\n",
    "    One = json_data['annotations'][0]['categories']['category_02']\n",
    "    label_list.append(One)\n",
    "    i+=1\n",
    "    if (i%100 == 0):\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DIX5btAbxTsB"
   },
   "outputs": [],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z6VNsX4phJ0"
   },
   "outputs": [],
   "source": [
    "y_data = np.array(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TXT7Bu6GpiXm"
   },
   "outputs": [],
   "source": [
    "y_data[y_data=='실외'] = 1\n",
    "y_data[y_data=='실내'] = 1\n",
    "y_data[y_data!='1'] = 0\n",
    "y_data = y_data.astype(int)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7QiPqa6pjpE"
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_data, test_size=0.33, random_state=42, stratify = y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyFe-CtRplpJ"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "x_train = x_train.astype('float')\n",
    "x_test = x_test.astype('float')\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-QU3C585d39"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCjkVkIF3E97"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class ParallelModel(nn.Module):\n",
    "    def __init__(self,num_emotions):\n",
    "        super().__init__()\n",
    "\n",
    "            # 1. conv block\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1= nn.Conv2d(in_channels=1,\n",
    "                   out_channels=16,\n",
    "                   kernel_size=3,\n",
    "                   stride=1,\n",
    "                   padding=1\n",
    "                  )\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.do = nn.Dropout2d(p=0.3)\n",
    "        # 2. conv block\n",
    "        self.conv2= nn.Conv2d(in_channels=16,\n",
    "                   out_channels=32,\n",
    "                   kernel_size=3,\n",
    "                   stride=1,\n",
    "                   padding=1\n",
    "                  )\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=4, stride=4)\n",
    "\n",
    "        # 3. conv block\n",
    "        self.conv3 = nn.Conv2d(in_channels=32,\n",
    "                   out_channels=64,\n",
    "                   kernel_size=3,\n",
    "                   stride=1,\n",
    "                   padding=1\n",
    "                  )\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "\n",
    "        # 4. conv block\n",
    "        self.conv4= nn.Conv2d(in_channels=64,\n",
    "                   out_channels=128,\n",
    "                   kernel_size=3,\n",
    "                   stride=1,\n",
    "                   padding=1\n",
    "                  )\n",
    "        self.bn4= nn.BatchNorm2d(128)\n",
    "\n",
    "        # Linear softmax layer\n",
    "        self.out_linear = nn.Linear(1792,num_emotions)\n",
    "        self.out_softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "\n",
    "        # transformer embedding\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "\n",
    "        out = self.do(self.mp1(out))\n",
    "        out = self.relu(self.bn2(self.conv2(out)))\n",
    "        out = self.do(self.mp2(out))\n",
    "        out = self.relu(self.bn3(self.conv3(out)))\n",
    "        out = self.do(self.mp2(out))\n",
    "        out = self.relu(self.bn4(self.conv4(out)))\n",
    "        out = self.do(self.mp2(out))\n",
    "\n",
    "\n",
    "        conv_embedding = torch.flatten(out, start_dim=1)\n",
    "\n",
    "        output_logits = self.out_linear(conv_embedding)\n",
    "        output_softmax = self.out_softmax(output_logits)\n",
    "        return output_logits, output_softmax  \n",
    "    \n",
    "model = ParallelModel(num_emotions=2).to(device)\n",
    "print('Number of trainable params: ',sum(p.numel() for p in model.parameters()) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5eUSfW1H3i6W"
   },
   "outputs": [],
   "source": [
    "EPOCHS=25\n",
    "DATASET_SIZE = x_train.shape[0]\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "##baseline에서 사용한 optimizer는 SGD이며 하이퍼파라미터는 다음과 같습니다.\n",
    "##Learning rate = 0.01, momentum=0.9\n",
    "OPTIMIZER = torch.optim.SGD(model.parameters(),lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scE71DHw3mYw"
   },
   "outputs": [],
   "source": [
    "def loss_fnc(predictions, targets):\n",
    "    return nn.CrossEntropyLoss()(input=predictions,target=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FLzvL0Pw4J73"
   },
   "outputs": [],
   "source": [
    "!pip install livelossplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wk6d43eG3t4_"
   },
   "outputs": [],
   "source": [
    "from livelossplot import PlotLosses\n",
    "liveloss = PlotLosses()\n",
    "\n",
    "logs = {}\n",
    "train_predicts = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # shuffle data\n",
    "    ind = np.random.permutation(DATASET_SIZE)\n",
    "\n",
    "    x_train = x_train[ind,:,:,:]\n",
    "    y_train = y_train[ind]\n",
    "\n",
    "    \n",
    "    #print(x_train.shape)\n",
    "    #print(y_train.shape)\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    iters = int(DATASET_SIZE / BATCH_SIZE)\n",
    "     \n",
    "    for i in range(iters):\n",
    "        ### indexing과정을 통해 작성된 Dataloader 코드\n",
    "        batch_start = i * BATCH_SIZE\n",
    "        batch_end = min(batch_start + BATCH_SIZE, DATASET_SIZE)\n",
    "        actual_batch_size = batch_end-batch_start\n",
    "        \n",
    "        x = x_train[batch_start:batch_end,:,:,:]\n",
    "        y = y_train[batch_start:batch_end]\n",
    "\n",
    "        #print(x.shape)\n",
    "        #print(y.shape)\n",
    "        \n",
    "        ###--------------------작성해야할 부분--------------------------------\n",
    "        ##1.train 데이터를 torch tensor로 타입 변경 및 gpu 설정\n",
    "        ##2.데이터를 모델의 입력으로 넣어 예측 후 loss 계산 및 optimization \n",
    "        x_tensor = torch.tensor(x,device=device).float()\n",
    "        y_tensor = torch.tensor(y, dtype=torch.long, device=device)\n",
    "\n",
    "        #print(x_tensor.shape)\n",
    "        #print(y_tensor.shape)\n",
    "        \n",
    "        # forward pass\n",
    "        output_logits, output_softmax = model(x_tensor)\n",
    "\n",
    "        train_predictions = torch.argmax(output_softmax,dim=1).cpu().numpy()\n",
    "        train_predicts.append(train_predictions)\n",
    "\n",
    "        # compute loss\n",
    "        loss = loss_fnc(output_logits, y_tensor)\n",
    "        \n",
    "        # compute gradients\n",
    "        OPTIMIZER.zero_grad()\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        OPTIMIZER.step()\n",
    "\n",
    "        epoch_loss += loss.item()*actual_batch_size/DATASET_SIZE\n",
    "\n",
    "    ###liveloss 함수를 사용하기 위한 코드들\n",
    "    logs['train_loss'] = epoch_loss\n",
    "        \n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()\n",
    "\n",
    "    print(epoch,loss.item(),accuracy_score(y, train_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ouzjYIWvbJ6"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predicts = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(x_test):\n",
    "        data = torch.FloatTensor(data).to(device).unsqueeze(1)\n",
    "\n",
    "        _ , output_softmax = model(data)\n",
    "        predictions = torch.argmax(output_softmax,dim=1).cpu().numpy()\n",
    "        predicts.append(predictions)\n",
    "\n",
    "print(f'predict_len:{len(predicts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2xrZnZspo5l"
   },
   "outputs": [],
   "source": [
    "#model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "\n",
    "#model.fit(x_train, y_train, batch_size=100, epochs=2)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predicts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nX5DRpZFMssj"
   },
   "outputs": [],
   "source": [
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fGsPKFxopqmp"
   },
   "outputs": [],
   "source": [
    "from lime import lime_image # 이미지 모듈\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm # LIME이 사용할 수 있게. \n",
    "\n",
    "explainer=lime_image.LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-enbEMjMpuv"
   },
   "outputs": [],
   "source": [
    "segmenter=SegmentationAlgorithm('slic', \n",
    "                               n_segments=100, #이미지 분할 조각 개수\n",
    "                               compactness=1, # 유사한 파트를 합치는 함수, log scale, default : 10\n",
    "                               sigma=1) # 스무딩 역할, 0과 1 사이의 float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOZmpWytPtZG"
   },
   "outputs": [],
   "source": [
    "mel_spec_db.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMKjzeUkNASi"
   },
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUbT6VFXMqCS"
   },
   "outputs": [],
   "source": [
    "olivetti_test_index=0\n",
    "\n",
    "exp=explainer.explain_instance(img, #데이터하나\n",
    "                              classifier_fn=model,# 2 class의 확률 반환 (softmax)\n",
    "                              top_labels=2, # 확률 기준 1-5위 분석\n",
    "                              num_samples=1000,# 샘플링 공간\n",
    "                              segmentation_fn=segmenter) # 이전에 lime의 형식에 맞게 래핑된 분할 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ta5h_FkCNJP3"
   },
   "outputs": [],
   "source": [
    "x_test[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6O-r_aeYPAx5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "두런두런_만번만승_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (dolearn-gpu)",
   "language": "python",
   "name": "dolearn-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
